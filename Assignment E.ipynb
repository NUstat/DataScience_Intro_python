{
 "cells": [
  {
   "cell_type": "raw",
   "id": "33dd6c4c",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Assignment E\"\n",
    "subtitle: \"Data cleaning & preparation\"\n",
    "format: \n",
    "  html:\n",
    "    toc: true\n",
    "    toc-title: Contents\n",
    "    toc-depth: 4\n",
    "    code-fold: show\n",
    "    self-contained: true\n",
    "jupyter: python3\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0116f49b",
   "metadata": {},
   "source": [
    "## Instructions {-}\n",
    "\n",
    "1. You may talk to a friend, discuss the questions and potential directions for solving them. However, you need to write your own solutions and code separately, and not as a group activity. \n",
    "\n",
    "2. Do not write your name on the assignment.\n",
    "\n",
    "3. Write your code in the *Code* cells and your answer in the *Markdown* cells of the Jupyter notebook. Ensure that the solution is written neatly enough to understand and grade.\n",
    "\n",
    "4. Use [Quarto](https://quarto.org/docs/output-formats/html-basics.html) to print the *.ipynb* file as HTML. You will need to open the command prompt, navigate to the directory containing the file, and use the command: `quarto render filename.ipynb --to html`. Submit the HTML file.\n",
    "\n",
    "5. The assignment is worth 100 points, and is due on **10th November 2023 at 11:59 pm**. \n",
    "\n",
    "6. There is a bonus question worth 20 points, and an ultra bonus question worth 30 points. However, there is no partial credit for these questions. You will get 20 or 0 for the bonus question, and 30 or 0 for the ultra-bonus question. If everything is correct, you can score 150 out of 100 in the assignment."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe7ea9bb",
   "metadata": {},
   "source": [
    "## Missing value imputation\n",
    "Read *Housing_missing_price.csv* as `housing_missing_price` and *Housing_complete.csv* as `housing_complete`. The datasets consist of housing features, like number of bedrooms, bathrooms, etc., and the price. Both datasets are exactly the same, except that *Housing_missing_price.csv* has some missing values of price. In this question, you will try different methods to impute the missing values of house price in the file *Housing_missing_price.csv*. You will use the prices in *Housing_complete.csv* to check the accuracy of your imputation.\n",
    "\n",
    "Note that you **cannot** use *Housing_complete.csv* to impute missing `price` in any of the questions. *Housing_complete.csv* is just to check the accuracy of your imputation, after you have done the imputation. Before imputing the missing `price`, assume you do not have *Housing_complete.csv*."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e217b24",
   "metadata": {},
   "source": [
    "### Number of missing values\n",
    "How many values of `price` are missing in *Housing_missing_price.csv*?\n",
    "\n",
    "*(3 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98549ab3",
   "metadata": {},
   "source": [
    "### Indices of missing values\n",
    "Find the row labels, where the `price` is missing. Assign those row labels as an array or a list to `index_null_price`.\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28a2b4ba",
   "metadata": {},
   "source": [
    "### Correlation of continuous variables with `price`\n",
    "Find the continuous variable having the highest correlation with `price`. Let the variable be $A_{cont}$.\n",
    "\n",
    "*(2 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8871c96f",
   "metadata": {},
   "source": [
    "### Missing value imputation using correlated continuous variable\n",
    "Make a scatterplot of `price` against $A_{cont}$, with a trendline. Using the trendline, impute the missing values of `price`. \n",
    "\n",
    "Plot the imputed `price` vs true `price` (from *Housing_complete.csv*) and print the RMSE (*Root mean squared error*). This is to be done only for the imputed values of `price`.\n",
    "\n",
    "*(10 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d91ac1",
   "metadata": {},
   "source": [
    "**Hint:**\n",
    "\n",
    "1. Make the trendline using non-missing values of `price` and $A_{cont}$.\n",
    "\n",
    "2. Impute the missing values of `price` only where they are missing, i.e., at row indices `index_null_price`.\n",
    "\n",
    "3. You may use the function below to plot the imputed price vs true price (*from Housing_complete.csv*) and print the RMSE. The function assumes that `housing_imputed_price` is the *Housing_missing_price.csv* dataset, with imputed values of `price`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64981570",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Defining a function to plot the imputed values vs actual values \n",
    "def plot_actual_vs_predicted():\n",
    "    fig, ax = plt.subplots(figsize=(9, 6))\n",
    "    plt.rc('xtick', labelsize=15) \n",
    "    plt.rc('ytick', labelsize=15) \n",
    "    x = housing_complete.loc[index_null_price,'price']/1e3\n",
    "    y = housing_imputed_price.loc[index_null_price,'price']/1e3\n",
    "    plt.scatter(x,y)\n",
    "    z=np.polyfit(x,y,1)\n",
    "    p=np.poly1d(z)\n",
    "    plt.plot(x,x,color='orange')\n",
    "    plt.xlabel('Actual price',fontsize=20)\n",
    "    plt.ylabel('Imputed price',fontsize=20)\n",
    "    ax.xaxis.set_major_formatter('${x:,.0f}k')\n",
    "    ax.yaxis.set_major_formatter('${x:,.0f}k')\n",
    "    rmse = np.sqrt(((x-y).pow(2)).mean())\n",
    "    print(\"RMSE= $\"+str(np.round(rmse,2))+\"k\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55db95c7",
   "metadata": {},
   "source": [
    "### Correlation of categorical variables with `price`\n",
    "Split the categorical columns of the *Housing_missing_price.csv*, such that they transform into dummy variables with each category corresponding to a column of 0s and 1s. The continuous variables remain as they were in the original dataset. Name this dataset as `housing_dummy`.\n",
    "\n",
    "Which categorical variable is the most highly correlated with `price`? Let that variable be $V_{cat}$.\n",
    "\n",
    "*(3 + 2 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0961d2d2",
   "metadata": {},
   "source": [
    "**Hint:** `pd.get_dummies()`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644154d5",
   "metadata": {},
   "source": [
    "### Missing value imputation using correlated categorical variable\n",
    "\n",
    "Impute the missing value of the `price` of a house as the average price of all the houses that have the same value of $V_{cat}$. For example, if $V_{cat}$ is `basement`, the missing price of a house that has a basement must be imputed as the average price of all the houses that have a basement, and the missing price of a house that lacks a basement must be imputed as the average price of all the houses that lack a basement.\n",
    "\n",
    "Plot the imputed `price` vs true `price` (from *Housing_complete.csv*) and print the RMSE (Root mean squared error). This is to be done only for the imputed values of `price`.\n",
    "\n",
    "*(10 points)*\n",
    "\n",
    "**Hint:** You may use the following code to get the mean house price for each level of the variable $V_{cat}$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f6bb25",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace 'Vcat' by the variable that you found to be the most correlated with 'price'\n",
    "price_Vcat = housing_missing_price['price'].groupby(housing_missing_price[Vcat]).mean()\n",
    "price_Vcat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5681bcc",
   "metadata": {},
   "source": [
    "### Missing value imputation using correlated continuous variable within the categories of correlated categorical variable\n",
    "Execute the following code. Note that the trendlines of `price` against `area` are different based on `airconditioning`.\n",
    "\n",
    "For each house, select the appropriate trendline to impute the missing `price`.\n",
    "\n",
    "Plot the imputed price vs true price (from *Housing_complete.csv*) and print the RMSE (Root mean squared error).  This is to be done only for the imputed values of `price`.\n",
    "\n",
    "*(15 points)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "14da9d22",
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(font_scale=1.25)\n",
    "a = sns.FacetGrid(housing_missing_price, hue = 'airconditioning',height=6, aspect=1.5)\n",
    "a.map(sns.regplot,'area','price')\n",
    "a.add_legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f3729017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"./Datasets/assnE_image.png\" width=\"675\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| echo: false\n",
    "\n",
    "# import image module\n",
    "from IPython.display import Image\n",
    "\n",
    "# get the image\n",
    "Image(url=\"./Datasets/assnE_image.png\",width=675)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f865c152",
   "metadata": {},
   "source": [
    "### **Bonus** question: Missing value imputation with KNN\n",
    "\n",
    "*(20 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32575066",
   "metadata": {},
   "source": [
    "#### Identifying optimal $K$ by $k$-fold cross validation\n",
    "\n",
    "You need to impute the missing `price` using the KNN ($K$-nearest neighbor) algorithm. However, before implementing the algorithm, find the optimal value of $K$, using $k$-fold cross-validation. Use all the variables in `housing_dummy`.\n",
    "\n",
    "Note that you **cannot** use *Housing_complete.csv* to find the optimal $K$."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5e1a562",
   "metadata": {},
   "source": [
    "Follow the $k$-fold cross validation procedure below to find the optimal $K$, i.e., the optimal number of nearest neighbors to consider when imputing missing values:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7bc25edb",
   "metadata": {},
   "source": [
    "1. Remove observations with missing `price` from `housing_dummy`. Let us call the resulting DataFrame as `housing_missing_removed`.\n",
    "\n",
    "2. Split `housing_missing_removed` into $k$-folds. Take $k=10$. Each fold will have one-tenth of the observations of `housing_missing_removed`.\n",
    "\n",
    "3. Iterate over the $K^{th}$ potential value of $K$, where $K \\in \\{1,2,...,50\\}$.\n",
    "\n",
    "   A. Iterate over the $i^{th}$ fold, where $i \\in \\{1,2,...,10\\}$\n",
    "\n",
    "      I. Assume that the all the `price` values of the $i^{th}$ fold are missing. Impute the value of `price` for an observation in the $i^{th}$ fold as the mean `price` of the $K$-nearest neighbors to the observation, where the neighbors are from among the observations in the remaining 9 folds. \n",
    "        \n",
    "      II. Compute the RMSE (Root mean squared error) for the $i^{th}$ fold. Let us denote the RMSE for $i^{th}$ fold, and considering $K$ nearest neighbors as $RMSE_{iK}$.\n",
    "\n",
    "   B. Find the average of the 10 RMSEs obtained in 3(A). Let us denote it as $RMSE_K$, i.e., RMSE for a given value of $K$. Then, $$RMSE_K = \\frac{1}{10} \\sum_{i=1}^{i=10} RMSE_{iK}$$\n",
    "\n",
    "4. The optimal value of $K$ is the one for which $RMSE_K$ is the minimum, i.e., $$K_{optimal}=\\underset{K \\in \\{1,...,50\\}}{\\operatorname{\\ argmin}} RMSE_K$$\n",
    "\n",
    "**Assumption to make it a bit simpler:**\n",
    "Ideally you should split the dataset randomly into $k$-folds. However, to make it simpler, you may assume that the data is already shuffled, and you may take the first $1/10^{th}$ observations to be in the $1^{st}$ fold, the next $1/10^{th}$ to be in the $2^{nd}$ fold and so on.\n",
    "\n",
    "**More explanation** about $k$-fold cross validation and the optimal $K$:\n",
    "\n",
    "You need to impute the missing price using the KNN (K-nearest neighbor) algorithm. However, before implementing the algorithm, find the optimal value of $K$, using $k$-fold cross-validation. This is an optimization method used for more advanced Machine Learning methods, such as KNN. In KNN, the number of neighbors, $K$, is called a hyperparameter, which cannot be optimized with a mathematical method. Therefore, it needs a more coding-based optimization method called cross-validation.  \n",
    "\n",
    "The idea of cross-validation is to split the dataset into subsets, called folds. After that a range of $K$ values is picked. For each $K$ value in the range, the KNN imputer is created and evaluated on each fold separately, returning an RMSE value for each fold. The average value of these RMSE values is the cross-validation RMSE value of that $K$ value. \n",
    "Cross-validation is a robust method to find the best $K$ in the KNN algorithm for the data at hand because it evaluates different parts of the data separately and takes the average of all results. It is called $k$-fold cross-validation, with $k$ as the number of folds we want to use, usually 3, 5 or 10. In this problem, we will use 10-fold cross-validation. \n",
    "Note that you need nested for loops to iterate over both each $K$ value and each fold for this algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a0e58a",
   "metadata": {},
   "source": [
    "#### Implementing KNN with optimal $K$\n",
    "Using the optimal value of $K = K_{optimal}$ obtained in the previous question, impute the missing values of `price` in `housing_missing_price`. Use all the variables in `housing_dummy` for implementing the KNN algorithm. Plot the imputed price vs true price (from *Housing_complete.csv*) and print the RMSE (Root mean squared error).  This is to be done only for the imputed values of `price`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fea440c",
   "metadata": {},
   "source": [
    "Answer check: The RMSE obtained with KNN should be lower than that obtained with any of the earlier methods. If not, then there may be some mistake in your KNN implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f96b047e",
   "metadata": {},
   "source": [
    "### **Ultra-bonus** question\n",
    "\n",
    "*(30 points)*\n",
    "\n",
    "Develop an algorithm to impute the missing `price`, such that it reduces the imputation RMSE to below $650k. Plot the imputed price vs true price (from *Housing_complete.csv*) and print the RMSE (Root mean squared error). This is to be done only for the imputed values of `price`.\n",
    "\n",
    "*Note that we have not attempted to solve this question yet. We are not sure if a solution exists. However, if you find a solution, you will get 30 points.*\n",
    "\n",
    "**Hint:** In the bonus question, all variables were given equal weights when imputing missing values with KNN. However, shouldn't some variables be given higher weight than others?\n",
    "\n",
    "\n",
    "*If you think you are successful, email your solution to krish@northwestern.edu for grading.*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d4307c1",
   "metadata": {},
   "source": [
    "## Binning\n",
    "Read *house_features_and_price.csv*. We will bin a couple of variables to better analyze the trend of `house_price` with those variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28d743",
   "metadata": {},
   "source": [
    "### Trend with `house_age`\n",
    "Make a scatterplot of `house_price` against `house_age`, along with the trendline. What is the trend indicated by the trendline?\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "431db248",
   "metadata": {},
   "source": [
    "### Trend with bins of `house_age`\n",
    "\n",
    "#### \n",
    "Bin `house_age` into 5 approximately equal-sized bins. \n",
    "\n",
    "*(3 points)*\n",
    "\n",
    "#### \n",
    "After binning, plot the mean `house_price` against the house age bins. \n",
    "\n",
    "*(3 points)*\n",
    "\n",
    "#### \n",
    "Is the trend seen with this plot different from that seen with the trendline in the previous question? If yes, then is one of the trends incorrect? Why or why not? \n",
    "\n",
    "*(4 points)*\n",
    "\n",
    "#### \n",
    "Is one of the trends more informative? If yes, then which one and how?\n",
    "\n",
    "*(4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8929f33b",
   "metadata": {},
   "source": [
    "### Trend with `number_convenience_stores`\n",
    "Make a barplot to visualize the mean `house_price` against `number_convenience_stores`. \n",
    "\n",
    "*(3 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0987a8d2",
   "metadata": {},
   "source": [
    "### Trend with bins of `number_convenience_stores`\n",
    "Bin `number_convenience_stores` into an appropriate number of bins such that the non-linear trend of the variation of `house_price` with the bins of `number_convenience_stores` is retained, while minimizing the number of bins.\n",
    "\n",
    "After binning, plot the mean `house_price` against the `number_convenience_stores` bins.\n",
    "\n",
    "*(8 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12fef6e5",
   "metadata": {},
   "source": [
    "### Size of `number_convenience_stores` bins\n",
    "Print the size of bins obtained in the previous question. Are the bins of approximately equal size? If not, is it reasonable to have bins of unequal sizes to visualize the trend of `house_price` with `number_convenience_stores`.?\n",
    "\n",
    "*(2 + 4 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f21e0f24",
   "metadata": {},
   "source": [
    "## Outliers\n",
    "\n",
    "### Identifying outlying prices\n",
    "Continue using `house_features_and_price.csv`. How many houses have outlying values of `house_price`. Are these houses extremely expensive or extremely cheap?\n",
    "\n",
    "*(6 + 2 points)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c4035ef",
   "metadata": {},
   "source": [
    "### Quick EDA\n",
    "How are these houses (identified in the previous question as outliers) different from the houses in the rest of the dataset, which might be making them extremely expensive / extremely cheap? Explore the data and mention your hypothesis.\n",
    "\n",
    "*(8 points)*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

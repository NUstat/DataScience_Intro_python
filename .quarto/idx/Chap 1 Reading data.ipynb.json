{"title":"Reading data","markdown":{"yaml":{"title":"Reading data","format":{"html":{"code-fold":false}},"jupyter":"python3"},"headingText":"Types of data - structured and unstructured","containsRefs":false,"markdown":"\n\n\nReading data is the first step to extract information from it. Data can exist broadly in two formats:\n\n(1) Structured data and,\n(2) Untructured data. \n\nStructured data is typically stored in a tabular form, where rows in the data correspond to \"observations\" and columns correspond to \"variables\". For example, the following dataset contains 5 observations, where each observation (or row) consists of information about a movie. The variables (or columns) contain different pieces of information about a given movie. As all variables for a given row are related to the same movie, the data below is also called as relational data.\n\nUnstructured data is data that is not organized in any pre-defined manner. Examples of unstructured data can be text files, audio/video files, images, Internet of Things (IoT) data, etc. Unstructured data is relatively harder to analyze as most of the analytical methods and tools are oriented towards structured data. However, an unstrctured data can be used to obtain structure data, which in turn can be analyzed. For example, an image can be converted to an array of pixels - which will be structured data. Machine learning algorithms can then be used on the array to classify the image as that of a dog or a cat. \n\nIn this course, we will focus on analyzing structured data.\n\n## Reading a *csv* file with *Pandas*\n\nStructured data can be stored in a variety of formats. The most popular format is *data_file_name.csv*, where the extension *csv* stands for comma separated values. The variable values of each observation are separated by a comma in a *.csv* file. In other words, the **delimiter** is a comma in a *csv* file. However, the comma is not visible when a *.csv* file is opened with Microsoft Excel. \n\n### Using the *read_csv* function\n\nWe will use functions from the *Pandas* library of *Python* to read data. Let us import *Pandas* to use its functions.\n\nNote that *pd* is the acronym that we will use to call a *Pandas* function. This acronym can be anything as desired by the user.\n\nThe function to read a *csv* file is [read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html). Let us read the dataset *movie_ratings.csv* in Python.\n\nNote that the file *movie_ratings.csv* is stored at the same location as the python script containing the above code. If that is not the case, we'll need to specify the location of the file as in the following code.\n\nNote that forward slash is used instead of backslash while specifying the path of the data file. Another option is to use two consecutive backslashes instead of a single forward slash.\n\n### Specifying the working directory\n\nIn case we need to read several datasets from a given location, it may be inconvenient to specify the path every time. In such a case we can change the current working directory to the location where the datasets are located.\n\nWe'll use the *os* library of *Python* to view and/or change the current working directory.\n\nThe function *getcwd()* stands for get current working directory.\n\nSuppose the dataset to be read is located at 'C:\\Users\\akl0407\\Desktop\\STAT303-1\\Quarto Book\\mybook\\Datasets'. Then, we'll use the function *chdir* to change the current working directory to this location.\n\nNow we can read the dataset from this location without mentioning the entire path as shown below.\n\n### Data overview and summary statistics\n\nOnce the data has been read, we may want to see what the data looks like. We'll use another *Pandas* function [head()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.head.html) to view the first few rows of the data.\n\nFor finding the number of rows and columns in the data, you may use the [shape()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.shape.html) function.\n\nThe *movie_ratings* dataset contains 2,809 observations (or rows) and 15 variables (or columns).\n\nFor obtaining summary statistics of data, you may use the [describe()](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.describe.html) function.\n\nAnswer the following questions based on the above table.\n\n## Reading other data formats - txt, html, json\n\nAlthough *csv* is a very popular format for strucutred data, data is found in several other formats as well. Some of the other data formats are *txt, html* and *json*.\n\n### Reading *txt* files\n\nThe *txt* format offers some additional flexibility as compared to the *csv* format. In the *csv* format, the delimiter is a comma (or the column values are separated by a comma). However, in a *txt* file, the delimiter can be anything as desired by the user. Let us read the file *movie_ratings.txt*, where the variable values are separated by a tab character.\n\nWe use the function *read_csv* to read a *txt* file. However, we mention the tab character ('\\t') as a separater of variable values.\n\nNote that there is no need to remember the argument name - *sep* for specifying the delimiter. You can always refer to the [read_csv()](https://pandas.pydata.org/docs/reference/api/pandas.read_csv.html) documentation to find the relevant argument.\n\n### Reading HTML data\n\nThe *Pandas* function *read_html* searches for tabular data, i.e., data contained within the *\\<table\\>* tags of an html file. Let us read the tables in the GDP per capita [page](https://en.wikipedia.org/wiki/List_of_countries_by_GDP_(nominal)_per_capita) on Wikipedia.\n\nAll the tables will be read and stored in the variable named as *tables*. Let us find the datatype of the variable *tables*.\n\nThe variable - tables is a list of all the tables read from the HTML data.\n\nThe in-built function *len* can be used to find the length of the list - *tables* or the number of tables read from the Wikipedia page. Let us check out the first table.\n\nThe above table doesn't seem to be useful. Let us check out the second table.\n\nThe above table contains the estimated GDP per capita of all countries. This is the table that is likely to be relevant to a user interested in analyzing GDP per capita of countries. Instead of reading all tables of an HTML file, we can focus the search to tables containing certain relevant keywords. Let us try searching all table containing the word 'Country'.\n\nThe *match* argument can be used to specify the kewyords to be present in the table to be read.\n\nOnly one table contains the keyword - 'Country'. Let us check out the table obtained.\n\nThe argument *match* helps with a more focussed search, and helps us discard irrelevant tables.\n\n### Reading JSON data\n\nJSON stands for JavaScript Object Notation, in which the data is stored and transmitted as plain text. Since the format is text only, JSON data can easily be exchanged between web applications, and used by any programming language. Unlinke the *csv* format, JSON supports a hierarchical data structure, and is easier to integrate with APIs.\n\nLets read JSON data on Ted Talks. The *Pandas* function [read_json] (https://pandas.pydata.org/docs/reference/api/pandas.read_json.html) converts JSON data to a dataframe.\n\n### Reading data from web APIs\n\n[API](https://en.wikipedia.org/wiki/API), an acronym for Application programming interface, is a way of transferring information between systems. Many websites have public APIs that provide data via JSON or other formats. For example, the [IMDb-API](https://imdb-api.com/) is a web service for receiving movies, serial, and cast information. API results are in the JSON format and include items such as movie specifications, ratings, Wikipedia page content, etc. One of these APIs contains ratings of the top 250 movies on IMDB. Let us read this data using the IMDB API. \n\nWe'll use the *get* function from the python library *requests* to request data from the API and obtain a response code. The response code will let us know if our request to pull data from this API was successful.\n\nWe have a response code of 200, which indicates that the request was successful.\n\nThe response object's JSON method will return a dictionary containing JSON parsed into native Python objects.\n\nThe *movie_data* contains only two keys. The *items* key seems likely to contain information about the top 250 movies. Let us convert the values of the *items* key (which is list of dictionaries) to a dataframe, so that we can view it in a tabular form.\n\nThis API provides the names of the top 250 movies along with the year of release, IMDB ratings, and cast information.\n\n## Writing data\n\nThe *Pandas* function *to_csv* can be used to write (or export) data to a *csv* or *txt* file. Below are some examples.\n\n**Example 1:** Let us export the movies data of the top 250 movies to a *csv* file.\n\nThe file *movie_data_exported.csv* will appear in the working directory.\n\n**Example 2:** Let us export the movies data of the top 250 movies to a *txt* file with a semi-colon as the delimiter.\n\n**Example 3:** Let us export the movies data of the top 250 movies to a *JSON* file.\n"},"formats":{"html":{"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":false,"code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","output-file":"Chap 1 Reading data.html"},"language":{},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.0.36","bibliography":["references.bib"],"theme":"cosmo","title":"Reading data","jupyter":"python3"},"extensions":{"book":{"multiFile":true}}},"pdf":{"execute":{"fig-width":5.5,"fig-height":3.5,"fig-format":"pdf","fig-dpi":300,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":false,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"engine":"jupyter"},"render":{"keep-tex":false,"keep-yaml":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"pdf","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":true,"merge-includes":true,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[]},"pandoc":{"pdf-engine":"xelatex","standalone":true,"variables":{"graphics":true,"tables":true},"default-image-extension":"pdf","to":"pdf","output-file":"Chap 1 Reading data.pdf"},"language":{},"metadata":{"block-headings":true,"bibliography":["references.bib"],"documentclass":"scrreprt","title":"Reading data","jupyter":"python3"},"extensions":{"book":{}}}}}